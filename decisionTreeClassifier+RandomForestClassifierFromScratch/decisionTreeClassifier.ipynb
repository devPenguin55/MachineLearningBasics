{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56971ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b05f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDataset = pd.read_csv('irisDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88177ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bee94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = irisDataset.drop(['species'], axis=1)\n",
    "y = irisDataset['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8311b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aedd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c87f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1c6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, threshold=None, value=None, leftChild=None, rightChild=None, feature=None):\n",
    "        self.leftChild = leftChild\n",
    "        self.rightChild = rightChild\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.feature = feature\n",
    "\n",
    "class decisionTreeClassifier:\n",
    "    def __init__(self, minSamplesSplit, minSamplesLeaf, maxDepth, X, y, features=None):\n",
    "        '''\n",
    "        minSamplesSplit -> amt samples needed to consider node for being split\n",
    "        minSamplesLeaf -> amt samples needed in a leaf after a split\n",
    "        '''\n",
    "        self.minSamplesSplit = minSamplesSplit # amt samples needed to consider node for being split\n",
    "        self.minSamplesLeaf = minSamplesLeaf # amt samples needed in a leaf after a split\n",
    "        self.maxDepth = maxDepth\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        if features is None:\n",
    "            self.features = range(self.X.shape[1])\n",
    "        else:\n",
    "            self.features = features\n",
    "\n",
    "        self.root = Node()\n",
    "\n",
    "    def printTree(self):\n",
    "        def recursePrint(node, depth):\n",
    "            indent = \"  \" * depth\n",
    "            if node.value is not None:\n",
    "                print(f\"{indent}Leaf -> Predict {node.value}\")\n",
    "                return\n",
    "            print(f\"{indent}if x[{node.feature}] <= {node.threshold}:\")\n",
    "            recursePrint(node.leftChild, depth + 1)\n",
    "            print(f\"{indent}else:\")\n",
    "            recursePrint(node.rightChild, depth + 1)\n",
    "\n",
    "        recursePrint(self.root, 0)\n",
    "\n",
    "    def createTree(self, curNode:Node, depth, subset):\n",
    "        if depth > self.maxDepth or len(subset) <= self.minSamplesSplit:\n",
    "            return Node(value=self.mostOccurrentSample(subset))\n",
    "        parentEntropy = self.entropy(subset)\n",
    "\n",
    "        logs = []\n",
    "        for feature in self.features:\n",
    "            for threshold in range(subset.shape[0]):\n",
    "                threshold = subset[threshold, feature]\n",
    "                leftSubset, rightSubset = self.split(subset, feature, threshold)\n",
    "\n",
    "                if len(leftSubset) >= self.minSamplesLeaf and len(rightSubset) >= self.minSamplesLeaf:\n",
    "                    weightedEntropy = (len(leftSubset)/len(subset))*(self.entropy(leftSubset)) \\\n",
    "                    + (len(rightSubset)/len(subset))*(self.entropy(rightSubset))\n",
    "                \n",
    "                    \n",
    "                    informationGain = parentEntropy - weightedEntropy\n",
    "                    logs.append((feature, threshold, informationGain))\n",
    "        \n",
    "        if not logs:\n",
    "            # becomes a leaf node\n",
    "            return Node(value=self.mostOccurrentSample(subset))\n",
    "\n",
    "        logs.sort(key=lambda x: x[-1], reverse=True)\n",
    "        best = logs[0]\n",
    "\n",
    "        leftSubset, rightSubset = self.split(subset, best[0], best[1])\n",
    "\n",
    "        curNode.threshold = best[1]\n",
    "        curNode.feature = best[0]\n",
    "\n",
    "        curNode.leftChild, curNode.rightChild = self.createTree(Node(), depth+1, leftSubset), self.createTree(Node(), depth+1, rightSubset)\n",
    "        return curNode\n",
    "\n",
    "    def mostOccurrentSample(self, subset):\n",
    "        values, counts = np.unique(subset[:, -1], return_counts=True)\n",
    "        return values[np.argmax(counts)]\n",
    "\n",
    "    def split(self, subset, feature, threshold):\n",
    "        left = np.array(np.empty((0, subset.shape[1])))\n",
    "        right = np.array(np.empty((0, subset.shape[1])))\n",
    "        for row in range(subset.shape[0]):\n",
    "            item = subset[row, feature]\n",
    "            \n",
    "            if item <= threshold:\n",
    "                left = np.vstack((left, np.expand_dims(subset[row], 0)))\n",
    "            else:\n",
    "                right = np.vstack((right, np.expand_dims(subset[row], 0)))\n",
    "\n",
    "        return [left, right]\n",
    "    \n",
    "    def entropy(self, subset):\n",
    "        # look at the y values\n",
    "        values, counts = np.unique(subset[:, -1], return_counts=True)\n",
    "        probabilities = counts / counts.sum()\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if x.shape == (self.X.shape[1],):\n",
    "            # only one data point to predict\n",
    "            x = np.expand_dims(x, 0)\n",
    "\n",
    "        predictions = np.array([])\n",
    "        for xInput in x:\n",
    "            curNode = self.root\n",
    "            while curNode.value is None:\n",
    "                # print(curNode.threshold, curNode.feature, curNode.value)\n",
    "                \n",
    "                if xInput[curNode.feature] >= curNode.threshold:\n",
    "                    curNode = curNode.rightChild\n",
    "                else:\n",
    "                    curNode = curNode.leftChild\n",
    "            predictions = np.append(predictions, curNode.value)\n",
    "        return predictions\n",
    "    \n",
    "    def fit(self):\n",
    "        subset = np.concatenate((self.X, self.y.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        self.root = self.createTree(self.root, 0, subset)\n",
    "\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, X, y, minSamplesSplit, minSamplesLeaf, maxDepth, nEstimators, bootstrap=True, nJobs=-1):\n",
    "        self.minSamplesSplit = minSamplesSplit\n",
    "        self.minSamplesLeaf = minSamplesLeaf \n",
    "        self.nEstimators = nEstimators\n",
    "        self.maxDepth = maxDepth\n",
    "        self.bootstrap = bootstrap\n",
    "        self.X, self.y = X, y\n",
    "\n",
    "        self.binFeatureAmount = int(np.ceil(self.X.shape[1] ** 0.5))\n",
    "    \n",
    "    def bootstrapData(self):\n",
    "        # randomly pick data with replacing to different estimators using different features\n",
    "        data = np.concatenate((self.X, self.y.reshape(-1, 1)), axis=1)       \n",
    "        bins = []\n",
    "        for _ in range(self.nEstimators):\n",
    "            # use the choice to get the data, combine with the amt of features for the finished bin\n",
    "            binDataIndices = np.random.choice(list(range(0, data.shape[0])), data.shape[0], replace=True)\n",
    "            binData = data[binDataIndices]\n",
    "            \n",
    "            featuresIndices = list(range(0, data.shape[1]-1))\n",
    "            features = np.random.choice(featuresIndices, self.binFeatureAmount, replace=False)\n",
    "            features = features.reshape(1, -1)\n",
    "            features = np.tile(features, (data.shape[0], 1))[:data.shape[0]]\n",
    "        \n",
    "            binData = np.hstack((binData, features))\n",
    "            \n",
    "            bins.append(binData)     \n",
    "        return bins       \n",
    "\n",
    "    def fit(self):        \n",
    "        bins = self.bootstrapData()\n",
    "        estimators = []\n",
    "        for estimatorIdx in tqdm(range(self.nEstimators)):\n",
    "            curBin = bins[estimatorIdx]\n",
    "            data, features = curBin[:, :(curBin.shape[1] - self.binFeatureAmount)], curBin[:, (curBin.shape[1] - self.binFeatureAmount):]\n",
    "            features = features.astype(int)\n",
    "            features = features[0, :]\n",
    "\n",
    "            curX, curY = data[:, :self.X.shape[1]], data[:, self.X.shape[1]:]\n",
    "            curY = curY.astype(int)\n",
    "            curY = curY.squeeze()\n",
    "\n",
    "            estimator = decisionTreeClassifier(\n",
    "                minSamplesSplit=self.minSamplesSplit,\n",
    "                minSamplesLeaf=self.minSamplesLeaf,\n",
    "                maxDepth=self.maxDepth,\n",
    "                X=curX,\n",
    "                y=curY,\n",
    "                features=features\n",
    "            )\n",
    "            \n",
    "            estimator.fit()\n",
    "            estimators.append(estimator)\n",
    "            \n",
    "        self.estimators = estimators\n",
    "\n",
    "            \n",
    "    def predict(self, x):\n",
    "        if x.shape == (self.X.shape[1],):\n",
    "            # only one data point to predict\n",
    "            x = np.expand_dims(x, 0)\n",
    "\n",
    "        predictions = np.array([])\n",
    "        for xInput in x:\n",
    "            estimatorPredictionsToBeAnalyzed = []\n",
    "            for estimator in self.estimators:\n",
    "                estimatorPredictionsToBeAnalyzed.append(estimator.predict(xInput))\n",
    "\n",
    "            values, counts = np.unique(estimatorPredictionsToBeAnalyzed, return_counts=True)\n",
    "            estimatorPredictionsMajorityVote = values[np.argmax(counts)]\n",
    "            \n",
    "            predictions = np.append(predictions, estimatorPredictionsMajorityVote)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acfc18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = decisionTreeClassifier(minSamplesSplit=25, minSamplesLeaf=3, maxDepth=3, X=xTrain, y=yTrain)\n",
    "dtc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f35c90bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    X=xTrain, y=yTrain, \n",
    "    minSamplesSplit=dtc.minSamplesSplit, minSamplesLeaf=dtc.minSamplesLeaf, \n",
    "    maxDepth=dtc.maxDepth, nEstimators=100, \n",
    "    bootstrap=True,\n",
    "    nJobs=-1\n",
    ")\n",
    "\n",
    "rfc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554a7090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if x[2] <= 1.9:\n",
      "  if x[0] <= 5.0:\n",
      "    Leaf -> Predict 0.0\n",
      "  else:\n",
      "    Leaf -> Predict 0.0\n",
      "else:\n",
      "  if x[2] <= 4.7:\n",
      "    if x[3] <= 1.5:\n",
      "      if x[0] <= 5.8:\n",
      "        Leaf -> Predict 1.0\n",
      "      else:\n",
      "        Leaf -> Predict 1.0\n",
      "    else:\n",
      "      Leaf -> Predict 1.0\n",
      "  else:\n",
      "    if x[2] <= 5.0:\n",
      "      Leaf -> Predict 2.0\n",
      "    else:\n",
      "      if x[0] <= 7.6:\n",
      "        Leaf -> Predict 2.0\n",
      "      else:\n",
      "        Leaf -> Predict 2.0\n"
     ]
    }
   ],
   "source": [
    "dtc.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddb42339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09166666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred = dtc.predict(xTrain).astype(int)\n",
    "\n",
    "trainDTCError = np.sum(yTrain != yPred) / len(yPred)\n",
    "trainDTCError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14fcac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred = dtc.predict(xTest).astype(int)\n",
    "testDTCError = np.sum(yTest != yPred) / len(yPred)\n",
    "testDTCError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66b201fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9083333333333333\n",
      "Test acc: 0.9\n"
     ]
    }
   ],
   "source": [
    "trainDTCPreds = dtc.predict(xTrain).astype(int)\n",
    "testDTCPreds = dtc.predict(xTest).astype(int)\n",
    "\n",
    "print(\"Train acc:\", np.mean(trainDTCPreds == yTrain))\n",
    "print(\"Test acc:\", np.mean(testDTCPreds == yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca4f02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred = rfc.predict(xTrain).astype(int)\n",
    "\n",
    "trainRfcError = np.sum(yTrain != yPred) / len(yPred)\n",
    "trainRfcError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b92231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred = rfc.predict(xTest).astype(int)\n",
    "testRfcError = np.sum(yTest != yPred) / len(yPred)\n",
    "testRfcError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ca7082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.95\n",
      "Test acc: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "trainRfcPreds = rfc.predict(xTrain).astype(int)\n",
    "testRfcPreds = rfc.predict(xTest).astype(int)\n",
    "\n",
    "print(\"Train acc:\", np.mean(trainRfcPreds == yTrain))\n",
    "print(\"Test acc:\", np.mean(testRfcPreds == yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f56f80b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                    DTC           RFC\n",
      "Train Error    ->   0.09          0.05\n",
      "Test  Error    ->   0.10          0.07\n",
      "\n",
      "Train Accuracy ->   0.91          0.95\n",
      "Test  Accuracy ->   0.90          0.93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "                    DTC           RFC\n",
    "Train Error    ->   {format(trainDTCError, \".2f\")}          {format(trainRfcError, \".2f\")}\n",
    "Test  Error    ->   {format(testDTCError, \".2f\")}          {format(testRfcError, \".2f\")}\n",
    "\n",
    "Train Accuracy ->   {format(np.mean(trainDTCPreds == yTrain), \".2f\")}          {format(np.mean(trainRfcPreds == yTrain), \".2f\")}\n",
    "Test  Accuracy ->   {format(np.mean(testDTCPreds == yTest), \".2f\")}          {format(np.mean(testRfcPreds == yTest), \".2f\")}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b07a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
